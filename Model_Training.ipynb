{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7n0FsssnMEX_",
    "outputId": "4fdf9385-0326-4ee6-c9ec-0ea0d59fb4fd"
   },
   "outputs": [],
   "source": [
    "!pip install kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "id": "Y9WKvnrHMJxV",
    "outputId": "9d0d7f88-a061-48c6-d928-a9a9495ca8d5"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-3sivKKsMRFz",
    "outputId": "1787679d-b586-4a1e-e4f7-be0b2a87ae95"
   },
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brTCqPEAMXE6",
    "outputId": "080e9507-c857-40d3-ca13-3297fbeab9ae"
   },
   "outputs": [],
   "source": [
    "!kaggle datasets download -d vuppalaadithyasairam/bone-fracture-detection-using-xrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vYvlk8zgMumx",
    "outputId": "9dd5e1b4-1fc2-4a1b-bb76-e82a9813f074"
   },
   "outputs": [],
   "source": [
    "!unzip fracture_datset.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tCHawkwfJesM",
    "outputId": "15477dcf-439a-4f6f-818b-7a05b1f8d5e6"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk(r'C:\\Users\\Riddhi\\Documents\\DIP - datasets\\Wrist_Dataset\\archive(6)'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T04:22:40.163015Z",
     "iopub.status.busy": "2022-11-14T04:22:40.162528Z",
     "iopub.status.idle": "2022-11-14T04:22:46.392242Z",
     "shell.execute_reply": "2022-11-14T04:22:46.391178Z",
     "shell.execute_reply.started": "2022-11-14T04:22:40.162936Z"
    },
    "id": "2pQKr98rJesN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T04:22:53.518698Z",
     "iopub.status.busy": "2022-11-14T04:22:53.517830Z",
     "iopub.status.idle": "2022-11-14T04:22:53.524914Z",
     "shell.execute_reply": "2022-11-14T04:22:53.523932Z",
     "shell.execute_reply.started": "2022-11-14T04:22:53.518655Z"
    },
    "id": "zGk9p2t8JesO"
   },
   "outputs": [],
   "source": [
    "train_path = r'C:\\Users\\Riddhi\\Documents\\DIP - datasets\\Wrist_Dataset\\archive (6)\\train'\n",
    "test_path = r'C:\\Users\\Riddhi\\Documents\\DIP - datasets\\Wrist_Dataset\\archive (6)\\val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2P1LyLDqe9M"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T04:22:55.416983Z",
     "iopub.status.busy": "2022-11-14T04:22:55.416611Z",
     "iopub.status.idle": "2022-11-14T04:22:55.423471Z",
     "shell.execute_reply": "2022-11-14T04:22:55.422124Z",
     "shell.execute_reply.started": "2022-11-14T04:22:55.416953Z"
    },
    "id": "lMByZJfPJesO"
   },
   "outputs": [],
   "source": [
    "train_datagen = image.ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "val_datagen= image.ImageDataGenerator(    rotation_range=15,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-14T04:22:55.716926Z",
     "iopub.status.busy": "2022-11-14T04:22:55.716558Z",
     "iopub.status.idle": "2022-11-14T04:22:59.252953Z",
     "shell.execute_reply": "2022-11-14T04:22:59.251844Z",
     "shell.execute_reply.started": "2022-11-14T04:22:55.716892Z"
    },
    "id": "Z92lMxB4JesO",
    "outputId": "7624e56d-113a-485f-f060-56dc5c79671c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8863 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size = (224,224),\n",
    "    batch_size = 4,\n",
    "    class_mode = 'binary')\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size = (224,224),\n",
    "    batch_size = 4,\n",
    "    shuffle=True,\n",
    "    class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-14T04:36:02.223324Z",
     "iopub.status.busy": "2022-11-14T04:36:02.222967Z",
     "iopub.status.idle": "2022-11-14T04:36:06.155199Z",
     "shell.execute_reply": "2022-11-14T04:36:06.154171Z",
     "shell.execute_reply.started": "2022-11-14T04:36:02.223296Z"
    },
    "id": "QtHnCvsFJesP",
    "outputId": "5cbc18bf-cd26-469b-fd96-3fcf9b65dbf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb3 (Functional)  (None, 7, 7, 1536)       10783535  \n",
      "                                                                 \n",
      " gaussian_noise (GaussianNoi  (None, 7, 7, 1536)       0         \n",
      " se)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1536)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               786944    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " gaussian_noise_1 (GaussianN  (None, 512)              0         \n",
      " oise)                                                           \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,573,040\n",
      "Trainable params: 788,481\n",
      "Non-trainable params: 10,784,559\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.EfficientNetB3(weights='imagenet', input_shape=(224,224,3), include_top=False)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable=False\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GaussianNoise(0.25))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(GaussianNoise(0.25))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T04:36:10.558630Z",
     "iopub.status.busy": "2022-11-14T04:36:10.557851Z",
     "iopub.status.idle": "2022-11-14T04:36:10.574264Z",
     "shell.execute_reply": "2022-11-14T04:36:10.572679Z",
     "shell.execute_reply.started": "2022-11-14T04:36:10.558593Z"
    },
    "id": "KiKTWWAbJesP"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy','Precision','Recall','AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FDzotQ6vJesR",
    "outputId": "4ac3ab81-94aa-448a-fdd3-d9cb0059d549"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.0348 - accuracy: 0.5900 - precision: 0.6162 - recall: 0.5810 - auc: 0.6445\n",
      "Epoch 1: val_loss improved from inf to 0.70624, saving model to best_model.h5\n",
      "50/50 [==============================] - 129s 2s/step - loss: 1.0348 - accuracy: 0.5900 - precision: 0.6162 - recall: 0.5810 - auc: 0.6445 - val_loss: 0.7062 - val_accuracy: 0.7283 - val_precision: 0.5970 - val_recall: 0.9875 - val_auc: 0.8055 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.7738 - accuracy: 0.6800 - precision: 0.7009 - recall: 0.7009 - auc: 0.7368\n",
      "Epoch 2: val_loss did not improve from 0.70624\n",
      "50/50 [==============================] - 106s 2s/step - loss: 0.7738 - accuracy: 0.6800 - precision: 0.7009 - recall: 0.7009 - auc: 0.7368 - val_loss: 0.8104 - val_accuracy: 0.5900 - val_precision: 0.4916 - val_recall: 0.7333 - val_auc: 0.6443 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.7301 - accuracy: 0.6800 - precision: 0.6818 - recall: 0.7212 - auc: 0.7330\n",
      "Epoch 3: val_loss improved from 0.70624 to 0.67849, saving model to best_model.h5\n",
      "50/50 [==============================] - 170s 3s/step - loss: 0.7301 - accuracy: 0.6800 - precision: 0.6818 - recall: 0.7212 - auc: 0.7330 - val_loss: 0.6785 - val_accuracy: 0.6850 - val_precision: 0.5955 - val_recall: 0.6625 - val_auc: 0.7507 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5852 - accuracy: 0.7150 - precision: 0.6875 - recall: 0.7097 - auc: 0.8026\n",
      "Epoch 4: val_loss improved from 0.67849 to 0.59376, saving model to best_model.h5\n",
      "50/50 [==============================] - 110s 2s/step - loss: 0.5852 - accuracy: 0.7150 - precision: 0.6875 - recall: 0.7097 - auc: 0.8026 - val_loss: 0.5938 - val_accuracy: 0.7067 - val_precision: 0.7025 - val_recall: 0.4625 - val_auc: 0.8123 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5057 - accuracy: 0.7450 - precision: 0.7957 - recall: 0.6981 - auc: 0.8411\n",
      "Epoch 5: val_loss improved from 0.59376 to 0.59100, saving model to best_model.h5\n",
      "50/50 [==============================] - 106s 2s/step - loss: 0.5057 - accuracy: 0.7450 - precision: 0.7957 - recall: 0.6981 - auc: 0.8411 - val_loss: 0.5910 - val_accuracy: 0.7167 - val_precision: 0.6250 - val_recall: 0.7292 - val_auc: 0.8046 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5747 - accuracy: 0.7300 - precision: 0.7037 - recall: 0.7755 - auc: 0.8045\n",
      "Epoch 6: val_loss did not improve from 0.59100\n",
      "50/50 [==============================] - 105s 2s/step - loss: 0.5747 - accuracy: 0.7300 - precision: 0.7037 - recall: 0.7755 - auc: 0.8045 - val_loss: 1.0139 - val_accuracy: 0.6483 - val_precision: 0.5838 - val_recall: 0.4208 - val_auc: 0.6831 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5666 - accuracy: 0.7300 - precision: 0.7290 - recall: 0.7573 - auc: 0.8081\n",
      "Epoch 7: val_loss did not improve from 0.59100\n",
      "50/50 [==============================] - 109s 2s/step - loss: 0.5666 - accuracy: 0.7300 - precision: 0.7290 - recall: 0.7573 - auc: 0.8081 - val_loss: 0.6963 - val_accuracy: 0.6967 - val_precision: 0.5967 - val_recall: 0.7458 - val_auc: 0.7786 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6240 - accuracy: 0.7100 - precision: 0.6796 - recall: 0.7368 - auc: 0.7729\n",
      "Epoch 8: val_loss did not improve from 0.59100\n",
      "50/50 [==============================] - 103s 2s/step - loss: 0.6240 - accuracy: 0.7100 - precision: 0.6796 - recall: 0.7368 - auc: 0.7729 - val_loss: 0.6862 - val_accuracy: 0.6683 - val_precision: 0.5639 - val_recall: 0.7542 - val_auc: 0.7818 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4891 - accuracy: 0.7500 - precision: 0.6869 - recall: 0.7816 - auc: 0.8443\n",
      "Epoch 9: val_loss did not improve from 0.59100\n",
      "50/50 [==============================] - 109s 2s/step - loss: 0.4891 - accuracy: 0.7500 - precision: 0.6869 - recall: 0.7816 - auc: 0.8443 - val_loss: 0.6632 - val_accuracy: 0.7017 - val_precision: 0.6151 - val_recall: 0.6792 - val_auc: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4272 - accuracy: 0.8250 - precision: 0.8252 - recall: 0.8333 - auc: 0.8904\n",
      "Epoch 10: val_loss did not improve from 0.59100\n",
      "50/50 [==============================] - 109s 2s/step - loss: 0.4272 - accuracy: 0.8250 - precision: 0.8252 - recall: 0.8333 - auc: 0.8904 - val_loss: 0.6689 - val_accuracy: 0.6917 - val_precision: 0.6141 - val_recall: 0.6167 - val_auc: 0.7742 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "lrp = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=2)\n",
    "filepath = 'best_model.h5'\n",
    "\n",
    "# Modify the monitor value of ModelCheckpoint callback\n",
    "checkpoint_monitor = 'val_loss'  # Use a different metric that doesn't involve tensors\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor=checkpoint_monitor, verbose=1, save_best_only=True,mode='min',save_weights_only=True )\n",
    "call = [checkpoint, lrp]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    steps_per_epoch=50,\n",
    "    callbacks=call\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-14T04:45:09.434045Z",
     "iopub.status.busy": "2022-11-14T04:45:09.433661Z",
     "iopub.status.idle": "2022-11-14T04:47:36.508122Z",
     "shell.execute_reply": "2022-11-14T04:47:36.507026Z",
     "shell.execute_reply.started": "2022-11-14T04:45:09.434013Z"
    },
    "id": "t0Tckzn8JesS",
    "outputId": "89fc69c2-df18-44e2-cf46-d062c1fdf8d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2216/2216 [==============================] - 1173s 529ms/step - loss: 0.3673 - accuracy: 0.8353 - precision: 0.8109 - recall: 0.8697 - auc: 0.9185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36730077862739563,\n",
       " 0.8352702260017395,\n",
       " 0.8108912706375122,\n",
       " 0.869723916053772,\n",
       " 0.9184583425521851]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-14T04:47:51.954614Z",
     "iopub.status.busy": "2022-11-14T04:47:51.954246Z",
     "iopub.status.idle": "2022-11-14T04:48:02.283911Z",
     "shell.execute_reply": "2022-11-14T04:48:02.282847Z",
     "shell.execute_reply.started": "2022-11-14T04:47:51.954582Z"
    },
    "id": "HzHWlBxRJesS",
    "outputId": "09fcaf3f-8fd6-4ef2-d6dd-c391fdeb4913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 79s 526ms/step - loss: 0.6895 - accuracy: 0.6883 - precision: 0.6047 - recall: 0.6375 - auc: 0.7655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6895389556884766,\n",
       " 0.6883333325386047,\n",
       " 0.6047430634498596,\n",
       " 0.637499988079071,\n",
       " 0.765532374382019]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "5dxuJLYcJesT",
    "outputId": "0120e472-d00c-4f3c-f45e-a63c0f214204"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "img = load_img('C:\\Users\\Riddhi\\Documents\\DIP - datasets\\Wrist_Dataset\\archive (6)\\val\\not fractured\\1-rotated3.jpg',target_size=(224,224))\n",
    "imag = img_to_array(img)\n",
    "imaga = np.expand_dims(imag,axis=0)\n",
    "ypred = model.predict(imaga)\n",
    "print(ypred)\n",
    "a=ypred[0]\n",
    "if a<0.5:\n",
    "      op=\"Fracture\"\n",
    "else:\n",
    "      op=\"Normal\"\n",
    "plt.imshow(img)\n",
    "print(\"THE UPLOADED X-RAY IMAGE IS: \"+str(op))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Au9Om4evJesT"
   },
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "#from pytesseract import pytesseract\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def browse_image():\n",
    "    file_path = filedialog.askopenfilename(filetypes=((\"Image files\", \"*.png;*.jpg;*.jpeg\"), (\"All files\", \"*.*\")))\n",
    "    if file_path:\n",
    "        image = Image.open(file_path)\n",
    "        image.thumbnail((400, 400))\n",
    "        photo = ImageTk.PhotoImage(image)\n",
    "        image_label.configure(image=photo)\n",
    "        image_label.image = photo\n",
    "\n",
    "def classify_image():\n",
    "    a=ypred[0]\n",
    "    if a<0.5:\n",
    "        result_label.configure(text=\"Fracture Detected\")\n",
    "    else:\n",
    "        result_label.configure(text=\"No Fracture Detected\")\n",
    "            \n",
    "window = tk.Tk()\n",
    "window.title(\"Fracture Detection\")\n",
    "window.geometry(\"600x400\")\n",
    "left_frame = tk.Frame(window)\n",
    "left_frame.pack(side=tk.LEFT, padx=20, pady=20)\n",
    "load_button = tk.Button(left_frame, text=\"Load Image\", command=browse_image)\n",
    "load_button.pack(pady=10)\n",
    "classify_button = tk.Button(left_frame, text=\"Classify Image\", command=classify_image)\n",
    "classify_button.pack(pady=10)\n",
    "\n",
    "\n",
    "right_frame = tk.Frame(window)\n",
    "right_frame.pack(side=tk.RIGHT, padx=20, pady=20)\n",
    "\n",
    "\n",
    "image_label = tk.Label(right_frame)\n",
    "image_label.pack()\n",
    "\n",
    "\n",
    "result_label = tk.Label(window, text=\"\")\n",
    "result_label.pack(pady=10)\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def browse_image():\n",
    "    file_path = filedialog.askopenfilename(filetypes=((\"Image files\", \"*.png;*.jpg;*.jpeg\"), (\"All files\", \"*.*\")))\n",
    "    if file_path:\n",
    "        image = Image.open(file_path)\n",
    "        image.thumbnail((400, 400))\n",
    "        photo = ImageTk.PhotoImage(image)\n",
    "        image_label.configure(image=photo)\n",
    "        image_label.image = photo\n",
    "\n",
    "def preprocess_image():\n",
    "    image = image_label.image\n",
    "    image_array = np.array(image)\n",
    "    processed_image = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)\n",
    "    processed_image = cv2.GaussianBlur(processed_image, (5, 5), 0)\n",
    "    \n",
    "    processed_image_label.configure(image=ImageTk.PhotoImage(Image.fromarray(processed_image)))\n",
    "    processed_image_label.image = processed_image_label.image\n",
    "    \n",
    "def classify_image():\n",
    "    result_label.configure(text=\"Classifying Image...\")\n",
    "\n",
    "window = tk.Tk()\n",
    "window.title(\"Fracture Detection\")\n",
    "window.geometry(\"800x400\")\n",
    "\n",
    "left_frame = tk.Frame(window)\n",
    "left_frame.pack(side=tk.LEFT, padx=20, pady=20)\n",
    "\n",
    "load_button = tk.Button(left_frame, text=\"Load Image\", command=browse_image)\n",
    "load_button.pack(pady=10)\n",
    "\n",
    "preprocess_button = tk.Button(left_frame, text=\"Preprocess Image\", command=preprocess_image)\n",
    "preprocess_button.pack(pady=10)\n",
    "\n",
    "classify_button = tk.Button(left_frame, text=\"Classify Image\", command=classify_image)\n",
    "classify_button.pack(pady=10)\n",
    "\n",
    "right_frame = tk.Frame(window)\n",
    "right_frame.pack(side=tk.RIGHT, padx=20, pady=20)\n",
    "\n",
    "image_label = tk.Label(right_frame)\n",
    "image_label.pack(side=tk.LEFT)\n",
    "\n",
    "processed_image_label = tk.Label(right_frame)\n",
    "processed_image_label.pack(side=tk.LEFT)\n",
    "\n",
    "result_label = tk.Label(window, text=\"\")\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "window.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
